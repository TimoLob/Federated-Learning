{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a46736f1-67cf-4a18-972d-cf0987e05ec5",
   "metadata": {},
   "source": [
    "# Vertical Federated Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ca90937-39dc-43bc-8249-9630eb061d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda.\n"
     ]
    }
   ],
   "source": [
    "# Importing essential libraries and modules for deep learning and visualization\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchinfo import summary\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Running on {device}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16440e9b-28ba-4ea2-977c-de7fcc09a4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fashion_MNIST\n",
    "fashion_labels = [\"T-shirt/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbf337d1-07d8-4666-afe1-64cd5b93d729",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "trainset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c85af4-b2d3-4c29-a33f-61dc9383d9b1",
   "metadata": {},
   "source": [
    "## Centralized machine learning model as benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7efd1e5-532e-4c89-866e-935dfe3a0f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BasicCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BasicCNN, self).__init__()\n",
    "        # Input: [batch_size, 1, 28, 28]\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3)  # Output: [batch_size, 32, 26, 26]\n",
    "        # Input: [batch_size, 32, 26, 26]\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3) # Output: [batch_size, 64, 11, 11]\n",
    "        self.fc1 = nn.Linear(64 * 5 * 5, 128)  # Flattening: [batch_size, 64*5*5]\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input: [batch_size, 1, 28, 28]\n",
    "        x = F.relu(self.conv1(x))\n",
    "        # Shape: [batch_size, 32, 26, 26]\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        # Shape: [batch_size, 32, 13, 13]\n",
    "        \n",
    "        x = F.relu(self.conv2(x))\n",
    "        # Shape: [batch_size, 64, 11, 11]\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        # Shape: [batch_size, 64, 5, 5]\n",
    "        \n",
    "        x = x.view(-1, 64 * 5 * 5) # Flattening\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7b5e41d-48c8-49fe-95a6-5cd0a4258cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "BasicCNN                                 [64, 10]                  --\n",
       "├─Conv2d: 1-1                            [64, 32, 26, 26]          320\n",
       "├─Conv2d: 1-2                            [64, 64, 11, 11]          18,496\n",
       "├─Linear: 1-3                            [64, 128]                 204,928\n",
       "├─Linear: 1-4                            [64, 10]                  1,290\n",
       "==========================================================================================\n",
       "Total params: 225,034\n",
       "Trainable params: 225,034\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 170.28\n",
       "==========================================================================================\n",
       "Input size (MB): 0.20\n",
       "Forward/backward pass size (MB): 15.11\n",
       "Params size (MB): 0.90\n",
       "Estimated Total Size (MB): 16.21\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BasicCNN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "num_epochs = 5\n",
    "train_batch_size = 64\n",
    "test_batch_size = 64\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=test_batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "summary(model, input_size=(train_batch_size, 1, 28, 28))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "582f8176-32b2-42a1-bbe2-ad75d26f5b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b09f25bde864b5fbb4c472a9ac8e50e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "767c5dff59bb43de8639fda5bc461eb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c56492affb243c3b0084d797206fbf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3506367a8e4c4ca8aaad2c6316185682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcc6138172f04b8a9d992423f9c220c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    for images, labels in tqdm(trainloader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5e54d5b-c7a5-4bb1-a2d7-3e7f8c3b30f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " T-shirt/top       0.81      0.89      0.85      1000\n",
      "     Trouser       0.99      0.98      0.99      1000\n",
      "    Pullover       0.83      0.88      0.85      1000\n",
      "       Dress       0.91      0.91      0.91      1000\n",
      "        Coat       0.87      0.81      0.84      1000\n",
      "      Sandal       0.99      0.98      0.98      1000\n",
      "       Shirt       0.75      0.68      0.72      1000\n",
      "     Sneaker       0.96      0.96      0.96      1000\n",
      "         Bag       0.97      0.99      0.98      1000\n",
      "  Ankle boot       0.96      0.97      0.96      1000\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Lists to store all predictions and true labels\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Iterate over all batches in the test loader\n",
    "    for images, labels in testloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Pass the images through the model to get predictions\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Get the class with the maximum probability as the predicted class\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        # Extend the all_preds list with predictions from this batch\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        \n",
    "        # Extend the all_labels list with true labels from this batch\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Print a classification report which provides an overview of the model's performance for each class\n",
    "print(classification_report(all_labels, all_preds, target_names=fashion_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c572f93c-b5f5-4b4f-81f7-4752d4463a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClientModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ClientModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3) \n",
    "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
    "\n",
    "        self.fc1 = nn.Linear(640, 128) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 640)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e84fcba-f61e-4ffa-9bb0-c23dc8d3898e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GlobalModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(256, 128)  \n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x)) \n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdda4a8d-aa0c-4f8a-ae68-50637d68e8b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ClientModel                              [64, 128]                 --\n",
       "├─Conv2d: 1-1                            [64, 32, 12, 26]          320\n",
       "├─Conv2d: 1-2                            [64, 64, 4, 11]           18,496\n",
       "├─Linear: 1-3                            [64, 128]                 82,048\n",
       "==========================================================================================\n",
       "Total params: 100,864\n",
       "Trainable params: 100,864\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 63.73\n",
       "==========================================================================================\n",
       "Input size (MB): 0.10\n",
       "Forward/backward pass size (MB): 6.62\n",
       "Params size (MB): 0.40\n",
       "Estimated Total Size (MB): 7.12\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_model = ClientModel()\n",
    "summary(c_model, input_size=(train_batch_size, 1, 14, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4e36eb0-a5e6-4d7b-806c-48608e0e4001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "GlobalModel                              [64, 10]                  --\n",
       "├─Linear: 1-1                            [64, 128]                 32,896\n",
       "├─Linear: 1-2                            [64, 64]                  8,256\n",
       "├─Linear: 1-3                            [64, 10]                  650\n",
       "==========================================================================================\n",
       "Total params: 41,802\n",
       "Trainable params: 41,802\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 2.68\n",
       "==========================================================================================\n",
       "Input size (MB): 0.07\n",
       "Forward/backward pass size (MB): 0.10\n",
       "Params size (MB): 0.17\n",
       "Estimated Total Size (MB): 0.34\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_model = GlobalModel()\n",
    "summary(g_model, input_size=(train_batch_size, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e1a5362-5713-4183-8314-186a8394d84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "torch.Size([64, 1, 14, 28])\n",
      "torch.Size([64, 1, 14, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-shirt/top\n"
     ]
    }
   ],
   "source": [
    "# Get input size of batch\n",
    "datatype = trainloader.dataset.data.dtype\n",
    "\n",
    "for X, y in trainloader:\n",
    "    print(X.shape, y.shape)\n",
    "    X_c1 = X[:,:,:14,:]\n",
    "    X_c2 = X[:,:,14:,:]\n",
    "    print(X_c1.shape)\n",
    "    print(X_c2.shape)\n",
    "    img = X_c1[0][0]\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.show()\n",
    "    img = X_c2[0][0]\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.show()\n",
    "    print(fashion_labels[y[0]])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4395c7d-ac29-44c4-9bd1-28c82aca08a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client:\n",
    "    def __init__(self,LocalModel):\n",
    "        \"\"\"\n",
    "        Parameters: LocalModel (class)\n",
    "        \"\"\"\n",
    "        self.local_model = LocalModel().to(device)\n",
    "    def forward(self,data):\n",
    "        data = data.to(device)\n",
    "        features = self.local_model(data)\n",
    "        return features\n",
    "\n",
    "\n",
    "\n",
    "class Server:\n",
    "    def __init__(self,GlobalModel):\n",
    "        self.global_model = GlobalModel().to(device)\n",
    "\n",
    "    def forward(self,X,y):\n",
    "        return self.global_model(concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "859b9292-70ca-4c64-91f7-f0143f454d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Server(GlobalModel)\n",
    "c1 = Client(ClientModel)\n",
    "c2 = Client(ClientModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3648c0b7-3054-4a8c-ae4d-ba37f712926f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c59b32e9217440698fa3d5c821c65bf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c555311afed4ca69b240d181bfc3e9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57eaabbcc04a499d830dd67ff8fb4871",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68ee5fe469ed4003ae6ea9be10ae9f19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb8fd678f14d4377be919570eea72d7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer_server = torch.optim.Adam(s.global_model.parameters(),lr=0.001)\n",
    "optimizer_client1 = torch.optim.Adam(c1.local_model.parameters(),lr=0.001)\n",
    "optimizer_client2 = torch.optim.Adam(c2.local_model.parameters(),lr=0.001)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    s.global_model.train()\n",
    "    c1.local_model.train()\n",
    "    c2.local_model.train()\n",
    "\n",
    "    for X, y in tqdm(trainloader):\n",
    "        y = y.to(device)\n",
    "        # Split images in top and bottom half\n",
    "        X_c1 = X[:,:,:14,:]\n",
    "        X_c2 = X[:,:,14:,:]\n",
    "        # Set optimizers to 0\n",
    "        optimizer_server.zero_grad()\n",
    "        optimizer_client1.zero_grad()\n",
    "        optimizer_client2.zero_grad()\n",
    "    \n",
    "        # Forward pass\n",
    "        features = [\n",
    "            c1.forward(X_c1), # First client has top half of image\n",
    "            c2.forward(X_c2)  # Second client has the bottom half\n",
    "        ]\n",
    "        \n",
    "        concat = torch.hstack(features) # Concat feature vectors that are the output from the clients\n",
    "        predictions = s.forward(concat,y) # Feed them into the global model\n",
    "    \n",
    "        loss = criterion(predictions,y)\n",
    "        loss.backward()\n",
    "    \n",
    "        optimizer_server.step()\n",
    "        optimizer_client1.step()\n",
    "        optimizer_client2.step()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ecc53e50-e007-4b08-822f-edc6ad7c5e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " T-shirt/top       0.90      0.83      0.86      1000\n",
      "     Trouser       0.99      0.98      0.99      1000\n",
      "    Pullover       0.92      0.85      0.88      1000\n",
      "       Dress       0.93      0.91      0.92      1000\n",
      "        Coat       0.89      0.87      0.88      1000\n",
      "      Sandal       0.99      0.97      0.98      1000\n",
      "       Shirt       0.71      0.83      0.76      1000\n",
      "     Sneaker       0.96      0.98      0.97      1000\n",
      "         Bag       0.97      0.98      0.98      1000\n",
      "  Ankle boot       0.98      0.97      0.97      1000\n",
      "\n",
      "    accuracy                           0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s.global_model.eval()\n",
    "c1.local_model.eval()\n",
    "c2.local_model.eval()\n",
    "\n",
    "# Lists to store all predictions and true labels\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Iterate over all batches in the test loader\n",
    "    for X, labels in testloader:\n",
    "        labels = labels.to(device)\n",
    "        X_c1 = X[:,:,:14,:]\n",
    "        X_c2 = X[:,:,14:,:]\n",
    "        # Pass the images through the model to get predictions\n",
    "        # Forward pass\n",
    "        features = [\n",
    "            c1.forward(X_c1), # First client has top half of image\n",
    "            c2.forward(X_c2)  # Second client has the bottom half\n",
    "        ]\n",
    "        \n",
    "        concat = torch.hstack(features) # Concat feature vectors that are the output from the clients\n",
    "        outputs = s.forward(concat,y) # Feed them into the global model\n",
    "        # Get the class with the maximum probability as the predicted class\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        # Extend the all_preds list with predictions from this batch\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        \n",
    "        # Extend the all_labels list with true labels from this batch\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Print a classification report which provides an overview of the model's performance for each class\n",
    "print(classification_report(all_labels, all_preds, target_names=fashion_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae8e714-b27c-447c-90f4-f61febb77e98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
