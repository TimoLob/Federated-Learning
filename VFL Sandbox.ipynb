{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a46736f1-67cf-4a18-972d-cf0987e05ec5",
   "metadata": {},
   "source": [
    "# Vertical Federated Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ca90937-39dc-43bc-8249-9630eb061d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda.\n"
     ]
    }
   ],
   "source": [
    "# Importing essential libraries and modules for deep learning and visualization\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchinfo import summary\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Running on {device}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16440e9b-28ba-4ea2-977c-de7fcc09a4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fashion_MNIST\n",
    "fashion_labels = [\"T-shirt/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbf337d1-07d8-4666-afe1-64cd5b93d729",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "trainset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c85af4-b2d3-4c29-a33f-61dc9383d9b1",
   "metadata": {},
   "source": [
    "## Centralized machine learning model as benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "b7efd1e5-532e-4c89-866e-935dfe3a0f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BasicCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BasicCNN, self).__init__()\n",
    "        # Input: [batch_size, 1, 28, 28]\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3)  # Output: [batch_size, 32, 26, 26]\n",
    "        # Input: [batch_size, 32, 26, 26]\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3) # Output: [batch_size, 64, 11, 11]\n",
    "        self.fc1 = nn.Linear(64 * 5 * 5, 128)  # Flattening: [batch_size, 64*5*5]\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input: [batch_size, 1, 28, 28]\n",
    "        x = F.relu(self.conv1(x))\n",
    "        # Shape: [batch_size, 32, 26, 26]\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        # Shape: [batch_size, 32, 13, 13]\n",
    "        \n",
    "        x = F.relu(self.conv2(x))\n",
    "        # Shape: [batch_size, 64, 11, 11]\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        # Shape: [batch_size, 64, 5, 5]\n",
    "        \n",
    "        x = x.view(-1, 64 * 5 * 5) # Flattening\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e7b5e41d-48c8-49fe-95a6-5cd0a4258cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "BasicCNN                                 [64, 10]                  --\n",
       "├─Conv2d: 1-1                            [64, 32, 26, 26]          320\n",
       "├─Conv2d: 1-2                            [64, 64, 11, 11]          18,496\n",
       "├─Linear: 1-3                            [64, 128]                 204,928\n",
       "├─Linear: 1-4                            [64, 10]                  1,290\n",
       "==========================================================================================\n",
       "Total params: 225,034\n",
       "Trainable params: 225,034\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 170.28\n",
       "==========================================================================================\n",
       "Input size (MB): 0.20\n",
       "Forward/backward pass size (MB): 15.11\n",
       "Params size (MB): 0.90\n",
       "Estimated Total Size (MB): 16.21\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "num_epochs = 5\n",
    "train_batch_size = 64\n",
    "test_batch_size = 64\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=test_batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "model = BasicCNN().to(device)\n",
    "summary(model, input_size=(train_batch_size, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "582f8176-32b2-42a1-bbe2-ad75d26f5b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61d5acc8a6bc433a8bcee50387beefda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feeea8d3da68401691769c262c504406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c805e8ddd7894b3abeb453f5b54fc507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63beb8c6379f42f8a30e37fb50a1ebfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5c84540b73c489f8335be4e8fc646fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    for images, labels in tqdm(trainloader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5e54d5b-c7a5-4bb1-a2d7-3e7f8c3b30f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " T-shirt/top       0.86      0.86      0.86      1000\n",
      "     Trouser       0.99      0.98      0.98      1000\n",
      "    Pullover       0.88      0.87      0.87      1000\n",
      "       Dress       0.90      0.92      0.91      1000\n",
      "        Coat       0.87      0.86      0.87      1000\n",
      "      Sandal       0.98      0.98      0.98      1000\n",
      "       Shirt       0.74      0.74      0.74      1000\n",
      "     Sneaker       0.95      0.97      0.96      1000\n",
      "         Bag       0.98      0.98      0.98      1000\n",
      "  Ankle boot       0.97      0.96      0.97      1000\n",
      "\n",
      "    accuracy                           0.91     10000\n",
      "   macro avg       0.91      0.91      0.91     10000\n",
      "weighted avg       0.91      0.91      0.91     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Lists to store all predictions and true labels\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Iterate over all batches in the test loader\n",
    "    for images, labels in testloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Pass the images through the model to get predictions\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Get the class with the maximum probability as the predicted class\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        # Extend the all_preds list with predictions from this batch\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        \n",
    "        # Extend the all_labels list with true labels from this batch\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Print a classification report which provides an overview of the model's performance for each class\n",
    "print(classification_report(all_labels, all_preds, target_names=fashion_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c572f93c-b5f5-4b4f-81f7-4752d4463a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClientModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ClientModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3) \n",
    "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
    "\n",
    "        self.fc1 = nn.Linear(640, 128) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 640)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9e84fcba-f61e-4ffa-9bb0-c23dc8d3898e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GlobalModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(256, 128)  \n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x)) \n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fdda4a8d-aa0c-4f8a-ae68-50637d68e8b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ClientModel                              [64, 128]                 --\n",
       "├─Conv2d: 1-1                            [64, 32, 12, 26]          320\n",
       "├─Conv2d: 1-2                            [64, 64, 4, 11]           18,496\n",
       "├─Linear: 1-3                            [64, 128]                 82,048\n",
       "==========================================================================================\n",
       "Total params: 100,864\n",
       "Trainable params: 100,864\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 63.73\n",
       "==========================================================================================\n",
       "Input size (MB): 0.10\n",
       "Forward/backward pass size (MB): 6.62\n",
       "Params size (MB): 0.40\n",
       "Estimated Total Size (MB): 7.12\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_model = ClientModel()\n",
    "summary(c_model, input_size=(train_batch_size, 1, 14, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d4e36eb0-a5e6-4d7b-806c-48608e0e4001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "GlobalModel                              [64, 10]                  --\n",
       "├─Linear: 1-1                            [64, 128]                 32,896\n",
       "├─Linear: 1-2                            [64, 64]                  8,256\n",
       "├─Linear: 1-3                            [64, 10]                  650\n",
       "==========================================================================================\n",
       "Total params: 41,802\n",
       "Trainable params: 41,802\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 2.68\n",
       "==========================================================================================\n",
       "Input size (MB): 0.07\n",
       "Forward/backward pass size (MB): 0.10\n",
       "Params size (MB): 0.17\n",
       "Estimated Total Size (MB): 0.34\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_model = GlobalModel()\n",
    "summary(g_model, input_size=(train_batch_size, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "9e1a5362-5713-4183-8314-186a8394d84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "torch.Size([64, 1, 14, 28])\n",
      "torch.Size([64, 1, 14, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sneaker\n"
     ]
    }
   ],
   "source": [
    "# Get input size of batch\n",
    "datatype = trainloader.dataset.data.dtype\n",
    "\n",
    "for X, y in trainloader:\n",
    "    print(X.shape, y.shape)\n",
    "    X_c1 = X[:,:,:14,:]\n",
    "    X_c2 = X[:,:,14:,:]\n",
    "    print(X_c1.shape)\n",
    "    print(X_c2.shape)\n",
    "    img = X_c1[0][0]\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.show()\n",
    "    img = X_c2[0][0]\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.show()\n",
    "    print(fashion_labels[y[0]])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f4395c7d-ac29-44c4-9bd1-28c82aca08a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client:\n",
    "    def __init__(self,LocalModel):\n",
    "        \"\"\"\n",
    "        Parameters: LocalModel (class)\n",
    "        \"\"\"\n",
    "        self.local_model = LocalModel().to(device)\n",
    "    def forward(self,data):\n",
    "        data = data.to(device)\n",
    "        features = self.local_model(data)\n",
    "        return features\n",
    "\n",
    "\n",
    "\n",
    "class Server:\n",
    "    def __init__(self,GlobalModel):\n",
    "        self.global_model = GlobalModel().to(device)\n",
    "\n",
    "    def forward(self,X,y):\n",
    "        return self.global_model(concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "859b9292-70ca-4c64-91f7-f0143f454d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Server(GlobalModel)\n",
    "c1 = Client(ClientModel)\n",
    "c2 = Client(ClientModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "3648c0b7-3054-4a8c-ae4d-ba37f712926f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb3cccf18eb042d295eab5a2398228bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c62abbafa8c440cfb01b3375fd4bb888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88ef08fcee9943b48261a6cc91e2c34d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3cca5806b5e47e6aecf22b5c31d3968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98dbe4f95640409fa1b1a3e8aa814ec3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer_server = torch.optim.Adam(s.global_model.parameters(),lr=0.001)\n",
    "optimizer_client1 = torch.optim.Adam(c1.local_model.parameters(),lr=0.001)\n",
    "optimizer_client2 = torch.optim.Adam(c2.local_model.parameters(),lr=0.001)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    s.global_model.train()\n",
    "    c1.local_model.train()\n",
    "    c2.local_model.train()\n",
    "\n",
    "    for X, y in tqdm(trainloader):\n",
    "        y = y.to(device)\n",
    "        # Split images in top and bottom half\n",
    "        X_c1 = X[:,:,:14,:]\n",
    "        X_c2 = X[:,:,14:,:]\n",
    "        # Set optimizers to 0\n",
    "        optimizer_server.zero_grad()\n",
    "        optimizer_client1.zero_grad()\n",
    "        optimizer_client2.zero_grad()\n",
    "    \n",
    "        # Forward pass\n",
    "        features = [\n",
    "            c1.forward(X_c1), # First client has top half of image\n",
    "            c2.forward(X_c2)  # Second client has the bottom half\n",
    "        ]\n",
    "        \n",
    "        concat = torch.hstack(features) # Concat feature vectors that are the output from the clients\n",
    "        predictions = s.forward(concat,y) # Feed them into the global model\n",
    "    \n",
    "        loss = criterion(predictions,y)\n",
    "        loss.backward()\n",
    "    \n",
    "        optimizer_server.step()\n",
    "        optimizer_client1.step()\n",
    "        optimizer_client2.step()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ecc53e50-e007-4b08-822f-edc6ad7c5e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " T-shirt/top       0.84      0.87      0.86      1000\n",
      "     Trouser       0.99      0.97      0.98      1000\n",
      "    Pullover       0.91      0.81      0.86      1000\n",
      "       Dress       0.86      0.92      0.89      1000\n",
      "        Coat       0.80      0.90      0.84      1000\n",
      "      Sandal       0.94      0.99      0.97      1000\n",
      "       Shirt       0.76      0.68      0.72      1000\n",
      "     Sneaker       0.95      0.93      0.94      1000\n",
      "         Bag       0.98      0.97      0.98      1000\n",
      "  Ankle boot       0.98      0.95      0.96      1000\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s.global_model.eval()\n",
    "c1.local_model.eval()\n",
    "c2.local_model.eval()\n",
    "\n",
    "# Lists to store all predictions and true labels\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Iterate over all batches in the test loader\n",
    "    for X, labels in testloader:\n",
    "        labels = labels.to(device)\n",
    "        X_c1 = X[:,:,:14,:]\n",
    "        X_c2 = X[:,:,14:,:]\n",
    "        # Pass the images through the model to get predictions\n",
    "        # Forward pass\n",
    "        features = [\n",
    "            c1.forward(X_c1), # First client has top half of image\n",
    "            c2.forward(X_c2)  # Second client has the bottom half\n",
    "        ]\n",
    "        \n",
    "        concat = torch.hstack(features) # Concat feature vectors that are the output from the clients\n",
    "        outputs = s.forward(concat,y) # Feed them into the global model\n",
    "        # Get the class with the maximum probability as the predicted class\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        # Extend the all_preds list with predictions from this batch\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        \n",
    "        # Extend the all_labels list with true labels from this batch\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Print a classification report which provides an overview of the model's performance for each class\n",
    "print(classification_report(all_labels, all_preds, target_names=fashion_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae8e714-b27c-447c-90f4-f61febb77e98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
